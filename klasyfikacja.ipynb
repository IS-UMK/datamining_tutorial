{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasyfikacja i ewaluacja\n",
    "\n",
    "TODO: opis  -- oraz dlaczego używamy ewaluacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as  np\n",
    "from sklearn import datasets\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]\n",
      " [ 5.4  3.9  1.7  0.4]\n",
      " [ 4.6  3.4  1.4  0.3]\n",
      " [ 5.   3.4  1.5  0.2]\n",
      " [ 4.4  2.9  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]]\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "['setosa' 'versicolor' 'virginica'] --> set([0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "print iris.data[:10]\n",
    "print iris.target[:10]\n",
    "print iris.target_names, '-->', set(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        50\n",
      " versicolor       1.00      1.00      1.00        50\n",
      "  virginica       1.00      1.00      1.00        50\n",
      "\n",
      "avg / total       1.00      1.00      1.00       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "clf.fit(iris.data, iris.target)\n",
    "\n",
    "target_predicted = clf.predict(iris.data)\n",
    "\n",
    "print metrics.classification.classification_report(iris.target, target_predicted, target_names=iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 procent skuteczności? Wygląda na to że dokonaliśmy przeuczenia gdyż nasz model trenowaliśmy oraz testowaliśmy na tym samym zbiorze danych. Innymi słowy ocenialiśmy go nie sprawdzając jak dobrze model generalizuje.\n",
    "\n",
    "Aby tego uniknąć podizelmy nasz zbiór na część testową oraz treningową w propocji 70-30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 45\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "            model_selection.train_test_split(iris.data, iris.target, test_size=0.3, random_state=0)\n",
    "    \n",
    "print X_train.shape[0], X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        16\n",
      " versicolor       1.00      0.94      0.97        18\n",
      "  virginica       0.92      1.00      0.96        11\n",
      "\n",
      "avg / total       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print metrics.classification.classification_report(y_test, y_pred , target_names=iris.target_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z poprzedniego rozdizału z wykresu punktowego pamiętamy, że setosa była kwiatem, który znacznie różnył się od pozostałych dwu gatunków, a najwięcej problemów będzie sprawiało rozróżnienie virginicy i versicolor. To samo widać z tego rapot klasyfikacji, że najwięcej błędów dokonuje się w tych właśnie klasach. Z definicji tych miar precision i recall możemy wysnuć wniosek, że versicolor był często myony versicolor, Przy czym własnie 6% przypaków  versicolor było błędnia zaklasyfikowanych jako Virginica.\n",
    "\n",
    "Aby zweryfikować, które klasy są ze soba mylone użyjmy Macierzy Konfuzji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 0 17  1]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "CM = metrics.classification.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print CM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6% przypadków to tylko jeden egzemplarz danych, który zostal błędnie sklasyfikowany. Abt móc wykorzystać cały zbiór danych do ewaluacji przyjrzymu się koncepcji, która nazywa się walidacją krzyżową (cross-validation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       0.00      0.00      0.00        50\n",
      " versicolor       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.00      0.00      0.00        50\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       0.00      0.00      0.00         0\n",
      " versicolor       0.00      0.00      0.00        50\n",
      "  virginica       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.00      0.00      0.00        50\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       0.00      0.00      0.00         0\n",
      " versicolor       0.00      0.00      0.00        50\n",
      "\n",
      "avg / total       0.00      0.00      0.00        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = model_selection.KFold(n_splits=3)\n",
    "\n",
    "for fold_no, (train_idx, test_idx) in enumerate(kf.split(X=iris.data, y = iris.target)):\n",
    "    X_train = iris.data[train_idx]\n",
    "    X_test = iris.data[test_idx]\n",
    "    Y_train = iris.target[train_idx]\n",
    "    Y_test = iris.target[test_idx]\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_pred = clf.predict(X_test)\n",
    "    print metrics.classification.classification_report(Y_test, Y_pred, target_names=iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dlaczego wyszły nam wszędzie zera? podzieliiśmy zbiór na trzy podzbiory. Wyjściowo miał on 150 egzemplarzy a w każdej klasie było 50 egzemplarzy. W zwiazku z czym podzieliliśmy zbiór danych w taki sposób, że trenowaliśmy klasyfikator na dwu kwiatach a testowaliśmy go na trzecim. Nie daliśmy zatem żadnych szans w naszej ewaluacji w teście.\n",
    "\n",
    "Moglibyśmy po prostu wymieszać zbiór wejściowy tak wybór kolejnych foldów wybierał losowe podzbiory. Ale wykorzystajmy tutaj Koncepcje losowania wartswowego (Stratified Sampling), które w przypadku niezbalansowanych danych zadbają o to aby prawodopobieństwo wybory danej klasy w zbiorze wejściowym było takie same w zbiorze testowym. Jako dodatkowy efekt cały zbiór danych będzie wybierany w losowej kolejności.\n",
    "\n",
    "> Niezbalansowane zbiory danych (czyli takie, w których mamy znacząco różne wielkości w różnych klasach) wymagają specjalnego traktowania\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        17\n",
      " versicolor       0.94      1.00      0.97        17\n",
      "  virginica       1.00      0.94      0.97        17\n",
      "\n",
      "avg / total       0.98      0.98      0.98        51\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        17\n",
      " versicolor       0.88      0.88      0.88        17\n",
      "  virginica       0.88      0.88      0.88        17\n",
      "\n",
      "avg / total       0.92      0.92      0.92        51\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        16\n",
      " versicolor       1.00      1.00      1.00        16\n",
      "  virginica       1.00      1.00      1.00        16\n",
      "\n",
      "avg / total       1.00      1.00      1.00        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "\n",
    "for fold_no, (train_idx, test_idx) in enumerate(kf.split(X=iris.data, y = iris.target)):\n",
    "    X_train = iris.data[train_idx]\n",
    "    X_test = iris.data[test_idx]\n",
    "    Y_train = iris.target[train_idx]\n",
    "    Y_test = iris.target[test_idx]\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_pred = clf.predict(X_test)\n",
    "    print metrics.classification.classification_report(Y_test, Y_pred, target_names=iris.target_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oczywiście na powyższy kod istnieje funkcja pomocnicza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.96666667,  0.96666667,  0.9       ,  0.96666667,  1.        ])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_scorer = metrics.make_scorer(metrics.accuracy_score)\n",
    "model_selection.cross_val_score(clf, iris.data, y=iris.target, cv=5, scoring=accuracy_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named graphviz",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-3813d87ba683>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named graphviz"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
